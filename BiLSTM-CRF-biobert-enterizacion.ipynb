{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Este modelo de red entrena un BiLSTM + CRF para la clasificación de NER sobre el corpus Biobert. Este modelo tiene como entrada a la red la enterización del conjunto X de entrenamiento y la enterización y categorización  de los vectores de etiquetas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\\fasttextspanish\\text_fasttext_skip_model_300_test.txt\n",
      "inputs\\libs2021\\mwrapper.py\n",
      "inputs\\libs2021\\tf2crf.py\n",
      "inputs\\libs2021\\utils.py\n",
      "inputs\\libs2021\\__pycache__\\mwrapper.cpython-310.pyc\n",
      "inputs\\libs2021\\__pycache__\\tf2crf.cpython-310.pyc\n",
      "inputs\\libs2021\\__pycache__\\utils.cpython-310.pyc\n",
      "inputs\\libscrf4\\crfta.py\n",
      "inputs\\libscrf4\\utils.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('inputs'):\n",
    "\n",
    "    for filename in filenames:\n",
    "\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Univalle\\AppData\\Local\\Temp\\ipykernel_18044\\2502262557.py:61: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('inputs/libs2021')\n",
    "\n",
    "#sys.path.append('/inputs/embedding')\n",
    "\n",
    "sys.path.append('inputs/libscrf4')\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "\n",
    "#from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "#from seqeval.metrics import classification_report as seqclarep\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "\n",
    "#from crfta import CRF as crf4\n",
    "\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "\n",
    "\n",
    "import datetime, os\n",
    "\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga del dataset Biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "biobert_dataset = load_dataset('Biobert_json.py', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9788 2\n",
      "2496 2\n",
      "2758 2\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 488 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##biobert\n",
    "\n",
    "bio_train_sents = list(biobert_dataset['train'])\n",
    "\n",
    "bio_test_sents = list(biobert_dataset['test'])\n",
    "\n",
    "bio_eval_sents = list(biobert_dataset['validation'])\n",
    "\n",
    "print(len(bio_train_sents),len(max(bio_train_sents,key=len)))\n",
    "\n",
    "print(len(bio_test_sents),len(max(bio_test_sents,key=len)))\n",
    "\n",
    "print(len(bio_eval_sents),len(max(bio_eval_sents,key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentencia': ['Abuela', 'materna', 'con', 'cancer', 'de', 'mama', 'a', 'los', '70', 'años', '.'], 'tag': [4, 19, 29, 0, 16, 16, 29, 29, 10, 8, 29]}\n"
     ]
    }
   ],
   "source": [
    "print(bio_train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biobert_dataset['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE  1. PREPROCESAMIENTO DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##biobert\n",
    "X_bio_train = [s['sentencia'] for s in bio_train_sents]\n",
    "\n",
    "y_bio_train = [s['tag'] for s in bio_train_sents]\n",
    "\n",
    "\n",
    "\n",
    "X_bio_test = [s['sentencia'] for s in bio_test_sents]\n",
    "\n",
    "y_bio_test = [s['tag'] for s in bio_test_sents]\n",
    "\n",
    "\n",
    "\n",
    "X_bio_eval = [s['sentencia'] for s in bio_eval_sents]\n",
    "\n",
    "y_bio_eval = [s['tag'] for s in bio_eval_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', 'Quiste', 'renal', 'izquierdo', 'complicado', '(', 'ecografia', 'noviembre', '2013', 'quistes', 'renales', 'bilaterales', ')', '.']\n",
      "[29, 29, 29, 29, 29, 29, 29, 2, 17, 29, 29, 29, 29, 29]\n"
     ]
    }
   ],
   "source": [
    "print(X_bio_train[2])\n",
    "\n",
    "print(y_bio_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9883\n",
      "32\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29}\n"
     ]
    }
   ],
   "source": [
    "##biobert\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "bio_words, bio_tagsss = set([]), set([])\n",
    "\n",
    " \n",
    "\n",
    "for s in (X_bio_train + X_bio_eval + X_bio_test):\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        bio_words.add(w.lower())\n",
    "\n",
    "\n",
    "\n",
    "for ts in (y_bio_train + y_bio_eval + y_bio_test):\n",
    "\n",
    "    for t in ts:\n",
    "\n",
    "        bio_tagsss.add(t)\n",
    "\n",
    "\n",
    "\n",
    "bio_word2index = {w: i + 2 for i, w in enumerate(list(bio_words))}\n",
    "\n",
    "bio_word2index['-PAD-'] = 0  # The special value used for padding\n",
    "\n",
    "bio_word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    "\n",
    " \n",
    "\n",
    "bio_tag2index = {t: i + 2 for i, t in enumerate(list(bio_tagsss))}\n",
    "\n",
    "bio_tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "\n",
    "bio_tag2index['-OOV-'] = 1  # The special value used to padding\n",
    "\n",
    "\n",
    "\n",
    "print (len(bio_word2index))\n",
    "\n",
    "print (len(bio_tag2index))\n",
    "\n",
    "\n",
    "\n",
    "np.save(\"outputs/bio_word2index.npy\", bio_word2index)\n",
    "\n",
    "np.save(\"outputs/bio_tag2index.npy\", bio_tag2index)\n",
    "\n",
    "print(bio_tagsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##biobert\n",
    "bio_train_sentences_X, bio_eval_sentences_X, bio_test_sentences_X, bio_train_tags_y, bio_eval_tags_y, bio_test_tags_y = [], [], [], [], [], []\n",
    "\n",
    "\n",
    "\n",
    "for s in X_bio_train:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_word2index[w.lower()])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_word2index['-OOV-'])\n",
    "\n",
    " \n",
    "\n",
    "    bio_train_sentences_X.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "for s in X_bio_eval:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_word2index[w.lower()])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_word2index['-OOV-'])\n",
    "\n",
    " \n",
    "\n",
    "    bio_eval_sentences_X.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "for s in X_bio_test:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_word2index[w.lower()])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_word2index['-OOV-'])\n",
    "\n",
    " \n",
    "\n",
    "    bio_test_sentences_X.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "for s in y_bio_train:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_tag2index[w])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_tag2index['-OOV-'])\n",
    "\n",
    "            \n",
    "\n",
    "    bio_train_tags_y.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "for s in y_bio_eval:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_tag2index[w])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_tag2index['-OOV-'])\n",
    "\n",
    "            \n",
    "\n",
    "    bio_eval_tags_y.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "for s in y_bio_test:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_tag2index[w])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_tag2index['-OOV-'])\n",
    "\n",
    "            \n",
    "\n",
    "    bio_test_tags_y.append(s_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Las matrices de los tags son de números indexados pequeños porque solo son 11 tags.  ({ORG, LOC, PER}  X IOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes de las Matrices:\n",
      "9788\n",
      "2758\n",
      "2496\n",
      "9788\n",
      "2758\n",
      "2496\n",
      "\n",
      "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
      "\n",
      "[130, 5763, 6682, 9481, 3078, 661, 921, 4433, 1757, 7525, 2314]\n",
      "[5554, 5517, 3201, 9388, 9308, 807, 9279, 6138, 8561, 1124, 3708, 8064, 6301, 1551, 8531, 2314]\n",
      "[71, 3078, 4688, 7525, 6682, 6681, 8028, 8349, 4506, 4217, 2314]\n",
      "[6, 21, 31, 2, 18, 18, 31, 31, 12, 10, 31]\n",
      "[10, 12, 5, 10, 12, 31, 5, 12, 10, 31, 10, 31, 7, 22, 22, 31]\n",
      "[31, 31, 12, 10, 31, 31, 31, 31, 31, 4, 31]\n"
     ]
    }
   ],
   "source": [
    "##biobert\n",
    "print(\"Longitudes de las Matrices:\")\n",
    "\n",
    "print(len(bio_train_sentences_X))\n",
    "\n",
    "print(len(bio_eval_sentences_X))\n",
    "\n",
    "print(len(bio_test_sentences_X))\n",
    "\n",
    "print(len(bio_train_tags_y))\n",
    "\n",
    "print(len(bio_eval_tags_y))\n",
    "\n",
    "print(len(bio_test_tags_y))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(bio_train_sentences_X[0])\n",
    "\n",
    "print(bio_eval_sentences_X[0])\n",
    "\n",
    "print(bio_test_sentences_X[0])\n",
    "\n",
    "print(bio_train_tags_y[0])\n",
    "\n",
    "print(bio_eval_tags_y[0])\n",
    "\n",
    "print(bio_test_tags_y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se procede a Normalizar las matrices con la longitud de la columna=MAX_LENGTH1 para que todas contengan el mismo numero de columnas, con la longitud máxima de palabras encontradas anteriormente y se agregan ceros a la derecha en las posiciones que hacen falta en el vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 130 5763 6682 9481 3078  661  921 4433 1757 7525 2314    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "(9788, 202)\n",
      "[5554 5517 3201 9388 9308  807 9279 6138 8561 1124 3708 8064 6301 1551\n",
      " 8531 2314    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "(2758, 202)\n",
      "[  71 3078 4688 7525 6682 6681 8028 8349 4506 4217 2314    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "(2496, 202)\n",
      "[ 6 21 31  2 18 18 31 31 12 10 31  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "(9788, 202)\n",
      "[10 12  5 10 12 31  5 12 10 31 10 31  7 22 22 31  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "(2758, 202)\n",
      "[31 31 12 10 31 31 31 31 31  4 31  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "(2496, 202)\n"
     ]
    }
   ],
   "source": [
    "##biobert\n",
    "\n",
    "\n",
    "\n",
    "MAX_LENGTH=202 \n",
    "\n",
    "bio_train_sentences_X = pad_sequences(bio_train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "bio_eval_sentences_X = pad_sequences(bio_eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "bio_test_sentences_X = pad_sequences(bio_test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "bio_train_tags_y = pad_sequences(bio_train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "bio_eval_tags_y = pad_sequences(bio_eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "bio_test_tags_y = pad_sequences(bio_test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    " \n",
    "\n",
    "print(bio_train_sentences_X[0])\n",
    "\n",
    "print(bio_train_sentences_X.shape)\n",
    "\n",
    "print(bio_eval_sentences_X[0])\n",
    "\n",
    "print(bio_eval_sentences_X.shape)\n",
    "\n",
    "print(bio_test_sentences_X[0])\n",
    "\n",
    "print(bio_test_sentences_X.shape)\n",
    "\n",
    "print(bio_train_tags_y[0])\n",
    "\n",
    "print(bio_train_tags_y.shape)\n",
    "\n",
    "print(bio_eval_tags_y[0])\n",
    "\n",
    "print(bio_eval_tags_y.shape)\n",
    "\n",
    "print(bio_test_tags_y[0])\n",
    "\n",
    "print(bio_test_tags_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "np.save(\"outputs/bio_train_sentences_X.npy\", bio_train_sentences_X)\n",
    "\n",
    "np.save(\"outputs/bio_eval_sentences_X.npy\", bio_eval_sentences_X)\n",
    "\n",
    "np.save(\"outputs/bio_test_sentences_X.npy\", bio_test_sentences_X)\n",
    "\n",
    "np.save(\"outputs/bio_train_tags_y.npy\", bio_train_tags_y)\n",
    "\n",
    "np.save(\"outputs/bio_eval_tags_y.npy\", bio_eval_tags_y)\n",
    "\n",
    "np.save(\"outputs/bio_test_tags_y.npy\", bio_test_tags_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categoricals(sequences, categories):\n",
    "\n",
    "    cat_sequences = []\n",
    "\n",
    "    for s in sequences:\n",
    "\n",
    "        cats = []\n",
    "\n",
    "        for item in s:\n",
    "\n",
    "            cats.append(np.zeros(categories))\n",
    "\n",
    "            cats[-1][item] = 1.0\n",
    "\n",
    "        cat_sequences.append(cats)\n",
    "\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "\n",
    "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
    "\n",
    "    encoded = to_categorical(data)\n",
    "\n",
    "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se realiza la categorización one-hot de las etiquetas o labels de entrenamiento, testeo y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "9788\n",
      "2496\n"
     ]
    }
   ],
   "source": [
    "##biobert\n",
    "\n",
    "bio_cat_train_tags_y = to_categoricals(bio_train_tags_y, len(bio_tag2index))\n",
    "\n",
    "bio_cat_eval_tags_y  = to_categoricals(bio_eval_tags_y, len(bio_tag2index))\n",
    "\n",
    "bio_cat_test_tags_y  = to_categoricals(bio_test_tags_y, len(bio_tag2index))\n",
    "\n",
    "\n",
    "\n",
    "print(bio_cat_train_tags_y[1])\n",
    "\n",
    "print(len(bio_cat_train_tags_y))\n",
    "\n",
    "print(len(bio_cat_test_tags_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTE 2. ENTRENAMIENTO DEL MODELO DE RED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##biobert\n",
    "from tf2crf import CRF as crf6\n",
    "\n",
    "from mwrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "\n",
    "input = Input(shape=(MAX_LENGTH,))\n",
    "\n",
    "word_embedding_size = 300\n",
    "\n",
    "\n",
    "\n",
    "# Embedding Layer\n",
    "\n",
    "#model = Embedding(input_dim=len(word2index), \n",
    "\n",
    "    #            output_dim=word_embedding_size, \n",
    "\n",
    "     #           input_length=MAX_LENGTH,\n",
    "\n",
    "     #           mask_zero=False)(input)\n",
    "\n",
    "\n",
    "\n",
    "model = Embedding(len(bio_word2index),\n",
    "\n",
    "                        EMBED_DIM,\n",
    "\n",
    "                        input_length=MAX_LENGTH,  \n",
    "\n",
    "                        #weights=[embedding_matrix],\n",
    "\n",
    "                        trainable=False,\n",
    "\n",
    "                        mask_zero=True)(input)\n",
    "\n",
    "\n",
    "\n",
    "# BI-LSTM Layer\n",
    "\n",
    "model = Bidirectional(LSTM(units=word_embedding_size, \n",
    "\n",
    "                     return_sequences=True, \n",
    "\n",
    "                     dropout=0.5, \n",
    "\n",
    "                     recurrent_dropout=0.5))(model)\n",
    "\n",
    "model  = Dropout(0.5, name='dropout_lstm')(model)\n",
    "\n",
    "model  = Dense(units=EMBED_DIM * 2, activation='relu')(model)\n",
    "\n",
    "model  = Dense(units=len(bio_tag2index), activation='relu')(model)\n",
    "\n",
    "    \n",
    "\n",
    "model  = Masking(mask_value=0.,input_shape=(MAX_LENGTH, len(bio_tag2index)))(model)\n",
    "\n",
    "    \n",
    "\n",
    "crf = crf6(units=len(bio_tag2index), name=\"ner_crf\")\n",
    "\n",
    "predictions = crf(model)\n",
    "\n",
    "\n",
    "\n",
    "base_model = Model(inputs=input, outputs=predictions)\n",
    "\n",
    "model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#biobert\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbio_train_sentences_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbio_cat_train_tags_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbio_eval_sentences_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbio_cat_eval_tags_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Univalle\\Downloads\\BiLSTM-CRF-biobert\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#biobert\n",
    "history= model.fit(bio_train_sentences_X, bio_cat_train_tags_y,\n",
    "\n",
    "                       validation_data=(bio_eval_sentences_X, bio_cat_eval_tags_y),\n",
    "\n",
    "                       batch_size=64, \n",
    "\n",
    "                       epochs=20,\n",
    "\n",
    "                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-LOC': 2, 'B-MISC': 3, 'I-ORG': 4, 'B-LOC': 5, 'B-ORG': 6, 'I-PER': 7, 'B-PER': 8, 'O': 9, 'I-MISC': 10, '-PAD-': 0, '-OOV-': 1}\n",
      "48/48 [==============================] - 37s 769ms/step\n",
      "(1517, 202)\n"
     ]
    }
   ],
   "source": [
    "print(bio_tag2index)\n",
    "\n",
    "y_pred= model.predict(bio_test_sentences_X)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'I-LOC', 3: 'B-MISC', 4: 'I-ORG', 5: 'B-LOC', 6: 'B-ORG', 7: 'I-PER', 8: 'B-PER', 9: 'O', 10: 'I-MISC', 0: '-PAD-', 1: '-OOV-'}\n",
      "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
     ]
    }
   ],
   "source": [
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "index2tag = {i: t for t, i in bio_tag2index.items()}\n",
    "\n",
    "print(index2tag)\n",
    "\n",
    "y1_pred = logits_to_tokens(y_pred, index2tag)\n",
    "\n",
    "print(y1_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1517, 202)\n"
     ]
    }
   ],
   "source": [
    "#print(Y_test[4])\n",
    "\n",
    "print(bio_test_tags_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tags = biobert_dataset['test'].features['tag'].feature.names\n",
    "print(len(name_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_tagname(indexs, tags):\n",
    "    return [tags[i] if isinstance(i, int) else i for i in indexs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y1_pred = [index_to_tagname(i, name_tags) for i in y1_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_y1_pred[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "index2tag = {i: t for t, i in bio_tag2index.items()}\n",
    "\n",
    "print(index2tag)\n",
    "\n",
    "y1_true = logits_to_tokens(bio_test_tags_y, index2tag)\n",
    "\n",
    "print(y1_true[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y1_true= [index_to_tagname(i, name_tags) for i in y1_true]\n",
    "\n",
    "print(new_y1_true[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B_CANCER_CONCEPT'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biobert_dataset['test'].features['tag'].feature.names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 75.3%\n",
      "   recall: 28.0%\n",
      " accuracy: 98.4%\n",
      " F1-score: 40.9%\n"
     ]
    }
   ],
   "source": [
    "#hh1 = seqclarep(results['Expected'], results['Predicted'])\n",
    "\n",
    "#print('\\nclassification_report:\\n', hh1)\n",
    "\n",
    "from seqeval.metrics import classification_report as seqclarep\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(\"precision: {:.1%}\".format(precision_score(new_y1_true, new_y1_pred)))\n",
    "\n",
    "print(\"   recall: {:.1%}\".format(recall_score(new_y1_true, new_y1_pred)))\n",
    "\n",
    "print(\" accuracy: {:.1%}\".format(accuracy_score(new_y1_true, new_y1_pred)))\n",
    "\n",
    "print(\" F1-score: {:.1%}\".format(f1_score(new_y1_true, new_y1_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.588026Z",
     "iopub.status.idle": "2024-11-19T00:32:33.588657Z",
     "shell.execute_reply": "2024-11-19T00:32:33.588487Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.588466Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "li1 = sum(new_y1_true, [])\n",
    "\n",
    "li2 = sum(new_y1_pred, [])\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "\n",
    "\n",
    "\n",
    "results['Expected'] = li1\n",
    "\n",
    "results['Predicted'] = li2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.590511Z",
     "iopub.status.idle": "2024-11-19T00:32:33.590865Z",
     "shell.execute_reply": "2024-11-19T00:32:33.590710Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.590693Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as eskclarep\n",
    "\n",
    "report = eskclarep(results['Expected'], results['Predicted'])\n",
    "\n",
    "#print('\\nclassification_report:\\n', report)\n",
    "\n",
    "\n",
    "\n",
    "print(report_to_df(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.592610Z",
     "iopub.status.idle": "2024-11-19T00:32:33.593002Z",
     "shell.execute_reply": "2024-11-19T00:32:33.592838Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.592818Z"
    }
   },
   "outputs": [],
   "source": [
    "test_samples = [\n",
    "\n",
    "    \"James Rodriguez es el jugador colombiano más importante con Radamel Falcao.\".split(),\n",
    "\n",
    "    \" Jugadores de la selección Colombia que juegan en el Reino Unido\".split()\n",
    "\n",
    "]\n",
    "\n",
    "#print(max(test_samples))\n",
    "\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.594672Z",
     "iopub.status.idle": "2024-11-19T00:32:33.595082Z",
     "shell.execute_reply": "2024-11-19T00:32:33.594900Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.594880Z"
    }
   },
   "outputs": [],
   "source": [
    "test_samples_X = []\n",
    "\n",
    "for s in test_samples:\n",
    "\n",
    "    s_int = []\n",
    "\n",
    "    for w in s:\n",
    "\n",
    "        try:\n",
    "\n",
    "            s_int.append(bio_word2index[w.lower()])\n",
    "\n",
    "        except KeyError:\n",
    "\n",
    "            s_int.append(bio_word2index['-OOV-'])\n",
    "\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "print(test_samples_X)\n",
    "\n",
    "print(test_samples_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.597357Z",
     "iopub.status.idle": "2024-11-19T00:32:33.598011Z",
     "shell.execute_reply": "2024-11-19T00:32:33.597635Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.597613Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.600028Z",
     "iopub.status.idle": "2024-11-19T00:32:33.600703Z",
     "shell.execute_reply": "2024-11-19T00:32:33.600419Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.600385Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(len(predictions))\n",
    "\n",
    "log_tokens = logits_to_tokens(predictions, {i: t for t, i in bio_tag2index.items()})\n",
    "\n",
    "print(log_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-19T00:32:33.602493Z",
     "iopub.status.idle": "2024-11-19T00:32:33.603151Z",
     "shell.execute_reply": "2024-11-19T00:32:33.602830Z",
     "shell.execute_reply.started": "2024-11-19T00:32:33.602800Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tabulate\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "\n",
    "heads1 = test_samples[0]\n",
    "\n",
    "body1 = [log_tokens[0][:len(test_samples[0])]]\n",
    "\n",
    "\n",
    "\n",
    "heads2 = test_samples[1]\n",
    "\n",
    "body2 = [log_tokens[1][:len(test_samples[1])]]\n",
    "\n",
    "\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(tabulate(body2, headers=heads2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## postagging Freeling 4.1\n",
    "\n",
    "\n",
    "\n",
    "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
    "\n",
    "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## pos tagger Stanford NLP\n",
    "\n",
    "\n",
    "\n",
    "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
    "\n",
    "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1529457,
     "sourceId": 2524269,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1530256,
     "sourceId": 2525700,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1937937,
     "sourceId": 6353546,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
